
import os
import json
import pandas as pd
import redis
import numpy as np
from datetime import datetime
from typing import Optional, List, Union
from alpaca.data.timeframe import TimeFrame, TimeFrameUnit

class RedisDataManager:
    def __init__(self, host='localhost', port=6379, db=0, password=None):
        # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®
        host = os.getenv("REDIS_HOST", host)
        port = int(os.getenv("REDIS_PORT", port))
        password = os.getenv("REDIS_PASSWORD", password)
        
        self.redis = redis.Redis(
            host=host, 
            port=port, 
            db=db, 
            password=password, 
            decode_responses=True
        )
        
    def get_key(self, symbol: str, timeframe: TimeFrame) -> str:
        """ç”Ÿæˆ Redis Key: market_data:{symbol}:{tf}"""
        tf_str = f"{timeframe.amount}{timeframe.unit.value}"
        return f"market_data:{symbol}:{tf_str}"

    def get_latest_timestamp(self, symbol: str, timeframe: TimeFrame) -> Optional[datetime]:
        """è·å– Redis ä¸­å­˜å‚¨çš„æœ€æ™šæ—¶é—´æˆ³"""
        key = self.get_key(symbol, timeframe)
        # è·å– ZSET ä¸­æœ€åä¸€ä¸ªå…ƒç´  (åˆ†æ•°ä¸ºæ—¶é—´æˆ³)
        result = self.redis.zrange(key, -1, -1, withscores=True)
        if result:
            _, score = result[0]
            return datetime.fromtimestamp(score)
        return None

    def save_bars(self, df: pd.DataFrame, symbol: str, timeframe: TimeFrame):
        """ä¿å­˜ K çº¿æ•°æ®åˆ° Redis ZSET"""
        if df.empty:
            return
            
        key = self.get_key(symbol, timeframe)
        pipeline = self.redis.pipeline()
        
        # ç¡®ä¿ timestamp åˆ—å­˜åœ¨
        if 'timestamp' in df.columns:
             # ç¡®ä¿æ˜¯ datetime ç±»å‹
            if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
                df['timestamp'] = pd.to_datetime(df['timestamp'])
        else:
            # å‡è®¾ index æ˜¯ timestamp
            df = df.reset_index()
            df.rename(columns={'index': 'timestamp'}, inplace=True)

        for _, row in df.iterrows():
            ts = row['timestamp']
            timestamp_score = ts.timestamp()
            
            # åºåˆ—åŒ–æ•°æ® (å»é™¤ timestamp å­—æ®µ,å› ä¸ºå®ƒæ˜¯ score)
            data_dict = row.drop('timestamp').to_dict()
            # å¤„ç† timestamp å¯¹è±¡æ— æ³• JSON åºåˆ—åŒ–çš„é—®é¢˜
            data_json = json.dumps(data_dict, default=str)
            
            # ZADD key score member
            pipeline.zadd(key, {data_json: timestamp_score})
            
        pipeline.execute()
        print(f"ğŸ’¾ Saved {len(df)} bars to Redis: {key}")

    def get_bars(self, symbol: str, timeframe: TimeFrame, start: datetime, end: datetime) -> pd.DataFrame:
        """ä» Redis è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„æ•°æ®"""
        key = self.get_key(symbol, timeframe)
        
        start_score = start.timestamp()
        end_score = end.timestamp()
        
        # ZRANGEBYSCORE key min max
        results = self.redis.zrangebyscore(key, start_score, end_score, withscores=True)
        
        if not results:
            return pd.DataFrame()
            
        data_list = []
        for member, score in results:
            data = json.loads(member)
            data['timestamp'] = datetime.fromtimestamp(score)
            data_list.append(data)
            
        df = pd.DataFrame(data_list)
        return df
