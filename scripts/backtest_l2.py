
import argparse
import pandas as pd
import numpy as np

from dotenv import load_dotenv
from datetime import datetime, timedelta
from alpaca.data.timeframe import TimeFrame, TimeFrameUnit
from strategies.engine import StrategyEngine
from config.settings import L2_SYMBOLS, L2_LOOKBACK_DAYS, get_feature_columns
from utils.logger import setup_logger

load_dotenv()
logger = setup_logger("l2_backtest")

def run_l2_backtest(days=90, top_n=3):
    logger.info(f"ğŸš€ å¼€å§‹ L2 (é€‰è‚¡) å›æµ‹, å›æº¯ {days} å¤©, Top/Bottom {top_n}")
    
    engine = StrategyEngine()
    
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    fetch_start = start_date - timedelta(days=L2_LOOKBACK_DAYS)
    
    # 1. è·å–æ•°æ® (æ‰€æœ‰ L2 æ ‡çš„) - æ‰¹é‡æŸ¥è¯¢
    logger.info(f"è·å– {len(L2_SYMBOLS)} ä¸ªæ ‡çš„æ•°æ®...")
    
    # âœ… æ‰¹é‡è·å–æ‰€æœ‰ L2 æ ‡çš„æ•°æ® (ä¸€æ¬¡æ€§æŸ¥è¯¢)
    df_all = engine.provider.fetch_bars(
        L2_SYMBOLS,  # æ‰¹é‡æŸ¥è¯¢åˆ—è¡¨
        TimeFrame(5, TimeFrameUnit.Minute), 
        fetch_start, 
        end_date,
        use_redis=True  # å¯ç”¨ Redis ç¼“å­˜
    )
    
    # æŒ‰æ ‡çš„åˆ†ç»„å¹¶æ·»åŠ ç‰¹å¾
    all_dfs = []
    if not df_all.empty:
        grouped = df_all.groupby('symbol')
        for sym, df in grouped:
            df = engine.l2_builder.add_all_features(df, is_training=False)
            all_dfs.append(df)
            
    if not all_dfs:
        logger.error("æ— æ•°æ®")
        return
        
    full_df = pd.concat(all_dfs)
    
    # 2. é¢„æµ‹ Rank
    logger.info("è®¡ç®— Rank åˆ†æ•°...")
    test_df = full_df[full_df['timestamp'] >= start_date].copy()
    
    if test_df.empty:
        logger.error("æµ‹è¯•åŒºé—´æ— æ•°æ®")
        return

    # æ‰¹é‡é¢„æµ‹
    cols = get_feature_columns(test_df)
    test_df['rank_score'] = engine.l2_model.predict(test_df[cols])
    
    # 3. æ¯æ—¥æ¨¡æ‹Ÿ (Tæ—¥æ”¶ç›˜é¢„æµ‹ -> T+1æ—¥ å¼€ç›˜è¿› -> T+1æ—¥ æ”¶ç›˜å‡º)
    test_df['date'] = test_df['timestamp'].dt.date
    dates = sorted(test_df['date'].unique())
    
    # åˆå§‹èµ„é‡‘åˆ†é…
    initial_balance = 10000.0
    balance = initial_balance
    
    history = []
    
    logger.info("å¼€å§‹æŒ‰æ—¥å›æµ‹ (Long Top N vs Short Bottom N)...")
    logger.info("äº¤æ˜“æ¨¡å¼: Tæ—¥æ”¶ç›˜ä¿¡å· -> T+1æ—¥ Openå¼€ä»“ -> T+1æ—¥ Closeå¹³ä»“ (æ—¥å†…)")
    
    for i in range(len(dates) - 1):
        curr_date = dates[i]   # Signal Date
        next_date = dates[i+1] # Execution Date
        
        # --- Signal Generation (Day T Close) ---
        day_df = test_df[test_df['date'] == curr_date]
        # å–æ¯ä¸ª symbol å½“å¤©æœ€åä¸€æ¡è®°å½•ä½œä¸º"æ”¶ç›˜å†³ç­–ç‚¹"
        dataset = day_df.sort_values('timestamp').groupby('symbol').tail(1)
        
        # Rank
        ranked = dataset.sort_values('rank_score', ascending=False)
        symbols = ranked['symbol'].tolist()
        
        if len(symbols) < top_n * 2:
            continue
            
        long_picks = symbols[:top_n]
        short_picks = symbols[-top_n:]
        
        # --- Execution (Day T+1 Intraday) ---
        next_day_df = test_df[test_df['date'] == next_date]
        
        daily_long_ret = 0.0
        daily_short_ret = 0.0
        long_count = 0
        short_count = 0
        
        # Calculate Long Returns
        for sym in long_picks:
            sym_df = next_day_df[next_day_df['symbol'] == sym].sort_values('timestamp')
            if sym_df.empty: continue
            
            # Open at first bar, Close at last bar
            open_price = sym_df.iloc[0]['open']
            close_price = sym_df.iloc[-1]['close']
            
            ret = (close_price - open_price) / open_price
            daily_long_ret += ret
            long_count += 1
            
        # Calculate Short Returns (Selling at Open, Buying back at Close)
        for sym in short_picks:
            sym_df = next_day_df[next_day_df['symbol'] == sym].sort_values('timestamp')
            if sym_df.empty: continue
            
            open_price = sym_df.iloc[0]['open']
            close_price = sym_df.iloc[-1]['close']
            
            # Short Return: (Open - Close) / Open
            ret = (open_price - close_price) / open_price
            daily_short_ret += ret
            short_count += 1
            
        avg_long = daily_long_ret / long_count if long_count > 0 else 0
        avg_short = daily_short_ret / short_count if short_count > 0 else 0
        
        # å‡è®¾ 50/50 èµ„é‡‘åˆ†é… (ä¸åšæ æ†ï¼ŒLongå’ŒShortå„å ä¸€åŠä»“ä½)
        # æˆ–è€… Long 100% + Short 100% (Market Neutral æ æ†)? 
        # ç®€å•èµ·è§: Total Ret = (Avg Long + Avg Short) / 2
        total_ret = (avg_long + avg_short) / 2
        
        balance *= (1 + total_ret)
        
        history.append({
            'date': next_date, 
            'value': balance, 
            'daily_ret': total_ret,
            'long_ret': avg_long,
            'short_ret': avg_short,
            'longs': long_picks,
            'shorts': short_picks
        })
    
    # ç»“æœ
    if not history:
        logger.warning("æ— äº¤æ˜“è®°å½•")
        return

    res_df = pd.DataFrame(history)
    total_ret = res_df['value'].iloc[-1] / initial_balance - 1
    
    print("\n" + "="*60)
    print("ğŸ“Š L2 é€‰è‚¡æ¨¡å‹ (Ranker) å›æµ‹ç»“æœ")
    print("="*60)
    print(f"å›æµ‹åŒºé—´: {dates[0]} ~ {dates[-1]}")
    print(f"æ¨¡å¼: T+1 Open -> Close (æ—¥å†…), Long Top {top_n} & Short Bottom {top_n}")
    print(f"ç´¯è®¡æ”¶ç›Š: {total_ret:+.2%}")
    print(f"æ—¥å‡æ”¶ç›Š: {res_df['daily_ret'].mean():+.2%}")
    print(f"æ—¥å‡åšå¤š: {res_df['long_ret'].mean():+.2%}")
    print(f"æ—¥å‡åšç©º: {res_df['short_ret'].mean():+.2%}")
    
    print("-" * 60)
    print("æœ€è¿‘ 5 å¤©ç»©æ•ˆ:")
    print(res_df[['date', 'value', 'daily_ret', 'long_ret', 'short_ret']].tail())

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--days", type=int, default=90)
    parser.add_argument("--top_n", type=int, default=3)
    args = parser.parse_args()
    
    run_l2_backtest(args.days, args.top_n)
