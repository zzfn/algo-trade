"""
L5 å…ƒç­–ç•¥è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨

é€šè¿‡å‚æ•°æ‰«æç”Ÿæˆå…ƒç­–ç•¥è®­ç»ƒæ•°æ®:
- å¯¹å†å²æ•°æ®çš„ä¸åŒæ—¶æœŸ
- æµ‹è¯•ä¸åŒå‚æ•°ç»„åˆ
- è®°å½•æ¯ä¸ªç»„åˆçš„è¡¨ç°
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from data.provider import DataProvider
from features.technical import FeatureBuilder
from features.macro import MacroFeatureBuilder
from models.engine import StrategyEngine
from models.constants import L2_SYMBOLS, MACRO_SYMBOLS
from alpaca.data.timeframe import TimeFrame, TimeFrameUnit
from dotenv import load_dotenv
from pathlib import Path
import json
from tqdm import tqdm

def extract_market_features(period_data, macro_data):
    """
    æå–å¸‚åœºç‰¹å¾ç”¨äºå…ƒç­–ç•¥
    
    Args:
        period_data: è¯¥æ—¶æœŸçš„ä»·æ ¼æ•°æ®
        macro_data: å®è§‚æ•°æ®
        
    Returns:
        å¸‚åœºç‰¹å¾å­—å…¸
    """
    # SPY ç‰¹å¾
    spy_return = macro_data['spy_return_1d'].iloc[-1] if 'spy_return_1d' in macro_data else 0
    spy_volatility = period_data['close'].pct_change().std() * np.sqrt(252)
    
    # VIX ç‰¹å¾
    vixy_level = macro_data['vixy_level'].iloc[-1] if 'vixy_level' in macro_data else 15
    
    # è¶‹åŠ¿ç‰¹å¾
    sma_20 = period_data['close'].rolling(20).mean().iloc[-1]
    sma_50 = period_data['close'].rolling(50).mean().iloc[-1]
    trend = 1 if sma_20 > sma_50 else -1
    
    # æ³¢åŠ¨ç‡
    recent_vol = period_data['close'].pct_change().tail(20).std()
    
    return {
        'spy_return_1d': spy_return,
        'spy_volatility': spy_volatility,
        'vixy_level': vixy_level,
        'market_trend': trend,
        'recent_volatility': recent_vol,
        'timestamp': period_data.index[-1]
    }

def simple_backtest(data, signal_threshold, top_n):
    """
    ç®€åŒ–çš„å›æµ‹å‡½æ•°
    
    Returns:
        æ€§èƒ½æŒ‡æ ‡å­—å…¸
    """
    # ç®€åŒ–ç‰ˆ: è®¡ç®—åŸºäºå‚æ•°çš„é¢„æœŸè¡¨ç°
    # å®é™…åº”è¯¥è¿è¡Œå®Œæ•´å›æµ‹,è¿™é‡Œä¸ºäº†é€Ÿåº¦ä½¿ç”¨ç®€åŒ–ç‰ˆ
    
    returns = data['close'].pct_change().dropna()
    
    # æ¨¡æ‹Ÿ: ä¸åŒå‚æ•°å¯¹æ”¶ç›Šçš„å½±å“
    # é˜ˆå€¼è¶Šé«˜ â†’ äº¤æ˜“è¶Šå°‘ä½†è´¨é‡è¶Šé«˜
    # top_n è¶Šå¤š â†’ åˆ†æ•£ä½†å¯èƒ½ç¨€é‡Šæ”¶ç›Š
    # risk_factor è¶Šé«˜ â†’ æ”¶ç›Šæ³¢åŠ¨è¶Šå¤§
    
    # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„å¯å‘å¼è¯„åˆ†
    # å®é™…åº”è¯¥è¿è¡ŒçœŸå®å›æµ‹
    base_return = returns.mean() * 252
    base_vol = returns.std() * np.sqrt(252)
    
    # å‚æ•°è°ƒæ•´
    threshold_factor = 1 + (signal_threshold - 0.45) * 0.5
    topn_factor = 1 - (top_n - 3) * 0.05
    
    # Risk Factor Removed
    
    adjusted_return = base_return * threshold_factor * topn_factor
    adjusted_vol = base_vol # No risk adjustment on vol without leverage factor
    
    sharpe = adjusted_return / (adjusted_vol + 1e-6) if adjusted_vol > 0 else 0
    
    return {
        'total_return': adjusted_return,
        'volatility': adjusted_vol,
        'sharpe_ratio': sharpe
    }

def generate_meta_training_data(days=180, window_size=30):
    """
    ç”Ÿæˆå…ƒç­–ç•¥è®­ç»ƒæ•°æ®
    
    Args:
        days: æ€»å¤©æ•°
        window_size: æ»‘åŠ¨çª—å£å¤§å°(å¤©)
    """
    load_dotenv()
    provider = DataProvider()
    
    print("=" * 60)
    print("ğŸ§  L5 å…ƒç­–ç•¥è®­ç»ƒæ•°æ®ç”Ÿæˆ")
    print("=" * 60)
    print(f"æ€»å¤©æ•°: {days}")
    print(f"çª—å£å¤§å°: {window_size} å¤©")
    print("=" * 60)
    
    # è·å–æ•°æ®
    end_date = datetime(2024, 12, 31)
    start_date = end_date - timedelta(days=days)
    
    print(f"\nğŸ“Š è·å–æ•°æ®...")
    print(f"   æ—¶é—´èŒƒå›´: {start_date.date()} åˆ° {end_date.date()}")
    
    # è·å– SPY æ•°æ®ç”¨äºå¸‚åœºç‰¹å¾
    spy_data = provider.fetch_bars(['SPY'], TimeFrame.Day, start_date, end_date)
    spy_data = spy_data.set_index('timestamp')
    
    # ç®€åŒ–: ç›´æ¥ä½¿ç”¨ SPY æ•°æ®ä½œä¸ºå¸‚åœºç‰¹å¾,ä¸ä¾èµ– MacroFeatureBuilder
    print(f"   SPY æ•°æ®: {len(spy_data)} è¡Œ")
    
    if len(spy_data) < window_size:
        print(f"âŒ é”™è¯¯: SPY æ•°æ®ä¸è¶³ (éœ€è¦è‡³å°‘ {window_size} å¤©)")
        return None
    
    # å‚æ•°æœç´¢ç©ºé—´
    param_grid = {
        'signal_threshold': [0.35, 0.40, 0.45, 0.50, 0.55],
        'top_n_trades': [2, 3, 4, 5]
    }
    
    total_combinations = (len(param_grid['signal_threshold']) * 
                         len(param_grid['top_n_trades']))
    
    print(f"\nğŸ” å‚æ•°ç»„åˆæ•°: {total_combinations}")
    print(f"   signal_threshold: {param_grid['signal_threshold']}")
    print(f"   top_n_trades: {param_grid['top_n_trades']}")
    
    # æ»‘åŠ¨çª—å£
    training_data = []
    num_windows = (days - window_size) // 5  # æ¯5å¤©ä¸€ä¸ªçª—å£
    
    print(f"\nâ³ å¼€å§‹ç”Ÿæˆæ•°æ®...")
    print(f"   çª—å£æ•°é‡: {num_windows}")
    print(f"   æ€»æµ‹è¯•æ¬¡æ•°: {num_windows * total_combinations}")
    
    for i in tqdm(range(num_windows), desc="çª—å£è¿›åº¦"):
        window_start = start_date + timedelta(days=i*5)
        window_end = window_start + timedelta(days=window_size)
        
        # è·å–è¯¥çª—å£çš„æ•°æ®
        window_spy = spy_data[(spy_data.index >= window_start) & (spy_data.index < window_end)]
        
        if len(window_spy) < 10:
            continue
        
        # ç®€åŒ–çš„å¸‚åœºç‰¹å¾æå–
        spy_return = window_spy['close'].pct_change().iloc[-1]
        spy_volatility = window_spy['close'].pct_change().std() * np.sqrt(252)
        recent_vol = window_spy['close'].pct_change().tail(20).std()
        
        # è¶‹åŠ¿
        sma_20 = window_spy['close'].rolling(20).mean().iloc[-1]
        sma_50 = window_spy['close'].rolling(min(50, len(window_spy))).mean().iloc[-1]
        trend = 1 if sma_20 > sma_50 else -1
        
        market_features = {
            'spy_return_1d': spy_return if not np.isnan(spy_return) else 0,
            'spy_volatility': spy_volatility if not np.isnan(spy_volatility) else 0.02,
            'vixy_level': 16.0,  # é»˜è®¤å€¼
            'market_trend': trend,
            'recent_volatility': recent_vol if not np.isnan(recent_vol) else 0.015,
            'timestamp': window_spy.index[-1]
        }
        
        # æµ‹è¯•æ¯ä¸ªå‚æ•°ç»„åˆ
        for threshold in param_grid['signal_threshold']:
            for top_n in param_grid['top_n_trades']:
                # è¿è¡Œç®€åŒ–å›æµ‹
                result = simple_backtest(window_spy, threshold, top_n)
                
                # è®°å½•æ‰€æœ‰ç»„åˆ
                training_data.append({
                    **market_features,
                    'signal_threshold': threshold,
                    'top_n_trades': top_n,
                    # 'l1_risk_factor': None,
                    'sharpe_ratio': result['sharpe_ratio'],
                    'total_return': result['total_return'],
                    'volatility': result['volatility']
                })
    
    # è½¬æ¢ä¸º DataFrame
    df = pd.DataFrame(training_data)
    
    if len(df) == 0:
        print(f"\nâŒ é”™è¯¯: æ²¡æœ‰ç”Ÿæˆä»»ä½•è®­ç»ƒæ•°æ®!")
        print(f"   è¯·æ£€æŸ¥æ•°æ®æ—¶é—´èŒƒå›´å’Œçª—å£å¤§å°")
        return None
    
    # ä¿å­˜æ•°æ®
    output_dir = Path('data')
    output_dir.mkdir(exist_ok=True)
    output_file = output_dir / 'meta_training_data.csv'
    
    df.to_csv(output_file, index=False)
    
    print(f"\nâœ… æ•°æ®ç”Ÿæˆå®Œæˆ!")
    print(f"   æ€»æ ·æœ¬æ•°: {len(df)}")
    print(f"   ä¿å­˜ä½ç½®: {output_file}")
    
    if len(df) > 0:
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   Sharpe èŒƒå›´: [{df['sharpe_ratio'].min():.2f}, {df['sharpe_ratio'].max():.2f}]")
        print(f"   å¹³å‡ Sharpe: {df['sharpe_ratio'].mean():.2f}")
    
    return df

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description='ç”Ÿæˆ L5 å…ƒç­–ç•¥è®­ç»ƒæ•°æ®')
    parser.add_argument('--days', type=int, default=180, help='æ€»å¤©æ•°')
    parser.add_argument('--window', type=int, default=30, help='çª—å£å¤§å°')
    args = parser.parse_args()
    
    generate_meta_training_data(args.days, args.window)
