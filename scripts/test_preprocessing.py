"""
æµ‹è¯•æ•°æ®é¢„å¤„ç†ç®¡é“ä¸ç‰¹å¾å·¥ç¨‹çš„é›†æˆ
"""
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from data.provider import DataProvider
from features.technical import FeatureBuilder
from alpaca.data.timeframe import TimeFrame
from dotenv import load_dotenv

def test_preprocessing_integration():
    """æµ‹è¯•é¢„å¤„ç†ç®¡é“æ˜¯å¦æ­£ç¡®é›†æˆåˆ°ç‰¹å¾å·¥ç¨‹ä¸­"""
    load_dotenv()
    
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•æ•°æ®é¢„å¤„ç†ç®¡é“é›†æˆ")
    print("=" * 60)
    
    provider = DataProvider()
    builder = FeatureBuilder()
    
    # è·å–å°‘é‡æµ‹è¯•æ•°æ®
    end_date = datetime(2024, 12, 31)
    start_date = end_date - timedelta(days=7)  # åªå– 7 å¤©æ•°æ®
    symbols = ['AAPL', 'MSFT']
    
    print(f"\nğŸ“Š è·å–æµ‹è¯•æ•°æ®...")
    print(f"   æ ‡çš„: {symbols}")
    print(f"   æ—¶é—´èŒƒå›´: {start_date.date()} -> {end_date.date()}")
    
    df_raw = provider.fetch_bars(symbols, TimeFrame.Hour, start_date, end_date)
    print(f"   åŸå§‹æ•°æ®: {len(df_raw)} è¡Œ")
    
    # æµ‹è¯• 1: ä½¿ç”¨é¢„å¤„ç†å™¨
    print(f"\nğŸ”¬ æµ‹è¯• 1: å¯ç”¨é¢„å¤„ç†å™¨")
    df_with_prep = builder.add_all_features(df_raw.copy(), is_training=False, use_preprocessor=True)
    print(f"   å¤„ç†åæ•°æ®: {len(df_with_prep)} è¡Œ")
    print(f"   æ–°å¢åˆ—: {[c for c in df_with_prep.columns if c.startswith('log_')]}")
    
    # æ£€æŸ¥ log returns
    if 'log_return_1p' in df_with_prep.columns:
        print(f"\n   âœ… Log Returns å·²è®¡ç®—:")
        print(f"      å‡å€¼: {df_with_prep['log_return_1p'].mean():.6f}")
        print(f"      æ ‡å‡†å·®: {df_with_prep['log_return_1p'].std():.6f}")
        print(f"      ç¼ºå¤±å€¼: {df_with_prep['log_return_1p'].isna().sum()}")
    else:
        print(f"\n   âŒ é”™è¯¯: log_return_1p æœªæ‰¾åˆ°!")
    
    # æµ‹è¯• 2: ä¸ä½¿ç”¨é¢„å¤„ç†å™¨ (å¯¹æ¯”)
    print(f"\nğŸ”¬ æµ‹è¯• 2: ç¦ç”¨é¢„å¤„ç†å™¨ (å¯¹æ¯”)")
    df_without_prep = builder.add_all_features(df_raw.copy(), is_training=False, use_preprocessor=False)
    print(f"   å¤„ç†åæ•°æ®: {len(df_without_prep)} è¡Œ")
    
    # å¯¹æ¯”
    print(f"\nğŸ“ˆ å¯¹æ¯”ç»“æœ:")
    print(f"   æ•°æ®è¡Œæ•°å·®å¼‚: {len(df_with_prep) - len(df_without_prep)} è¡Œ")
    print(f"   (é¢„å¤„ç†å™¨ä¼šç§»é™¤å¼‚å¸¸å€¼,æ‰€ä»¥è¡Œæ•°å¯èƒ½å‡å°‘)")
    
    # æ£€æŸ¥ç‰¹å¾åˆ†å¸ƒ
    print(f"\nğŸ“Š ç‰¹å¾ç»Ÿè®¡ (å¯ç”¨é¢„å¤„ç†):")
    feature_cols = [c for c in df_with_prep.columns if c not in 
                   ['timestamp', 'symbol', 'open', 'high', 'low', 'close', 'volume']]
    print(f"   æ€»ç‰¹å¾æ•°: {len(feature_cols)}")
    print(f"   ç¼ºå¤±å€¼ç»Ÿè®¡:")
    missing = df_with_prep[feature_cols].isna().sum()
    if missing.sum() > 0:
        print(missing[missing > 0])
    else:
        print(f"      âœ… æ— ç¼ºå¤±å€¼")
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆ!")
    return df_with_prep

if __name__ == "__main__":
    test_preprocessing_integration()
